{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3970186",
   "metadata": {},
   "source": [
    "# TOPICS IN ARTIFICIAL INTELLIGENCE PROJECT - 1\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "#### Implement a simple CNN architecture (not using pre-existing complete network architecture nor multi-layer blocks). Apply your model to the MNIST dataset and compare your results with existing CNN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1d6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d65bb",
   "metadata": {},
   "source": [
    "## STEP 1\n",
    "\n",
    "### Loading MNIST dataset which contains 60,000 training examples and 10,000 testing examples. \n",
    "\n",
    "### Then, this 60,000 examples are divided into 55,000 for training and 5,000 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece0f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_mnist, y_train_mnist), (X_test, y_test_mnist) = tf.keras.datasets.mnist.load_data()\n",
    "y_train = y_train_mnist\n",
    "y_test = y_test_mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f767d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train_mnist[:-5000], X_train_mnist[-5000:]\n",
    "y_train, y_valid = y_train_mnist[:-5000], y_train_mnist[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c5a47",
   "metadata": {},
   "source": [
    "## STEP 2\n",
    "\n",
    "### The data is standardized by normalizing and reshaping the data.\n",
    "\n",
    "### One hot encoding is done to the output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c928f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting from int to float\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_valid = X_valid.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# # normalize pizel values 0-1\n",
    "# X_train = X_train/255.0\n",
    "# X_valid = X_valid/255.0\n",
    "# X_test = X_test/255.0\n",
    "\n",
    "mean = X_train.mean(axis=0, keepdims=True)\n",
    "stdDev = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - mean) / stdDev\n",
    "X_valid = (X_valid - mean) / stdDev\n",
    "X_test = (X_test - mean) / stdDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb63573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data reshaped from  (55000, 28, 28) to  (55000, 28, 28, 1)\n",
      "Validation data reshaped from  (5000, 28, 28) to  (5000, 28, 28, 1)\n",
      "Test data reshaped from  (10000, 28, 28) to  (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape dataset to have a single channel\n",
    "train,valid,test = X_train.shape ,X_valid.shape,X_test.shape\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1], X_valid.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "print('Training data reshaped from ',train,'to ',X_train.shape)\n",
    "print('Validation data reshaped from ',valid,'to ',X_valid.shape)\n",
    "print('Test data reshaped from ',test,'to ',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ffbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of output labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_valid = to_categorical(y_valid)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b3c19",
   "metadata": {},
   "source": [
    "## STEP 3\n",
    "\n",
    "### Various model architectures are defined. This includes variation in layers and optmizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a27569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               94200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,982\n",
      "Trainable params: 97,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential ([  \n",
    "  Conv2D(filters=6, kernel_size=5, padding='SAME', activation='relu',input_shape=[28, 28, 1]),\n",
    "  MaxPool2D(pool_size=2),\n",
    "  Conv2D(filters=16, kernel_size=5, padding='SAME', activation='relu'),\n",
    "  MaxPool2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(units=120, activation='relu'),\n",
    "  Dense(units=10, activation='softmax'),\n",
    "    \n",
    "])\n",
    "\n",
    "model1.compile(\n",
    "    loss = 'categorical_crossentropy', \n",
    "    optimizer = 'adam', \n",
    "    metrics = ['accuracy']) \n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7ccc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                200768    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,162\n",
      "Trainable params: 257,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential ([  \n",
    "  Conv2D(filters=32, kernel_size=3, padding='SAME', activation='relu',input_shape=[28, 28, 1]),\n",
    "  MaxPool2D(pool_size=2),\n",
    "  Conv2D(filters=64, kernel_size=3, padding='SAME', activation='relu'),\n",
    "  MaxPool2D(pool_size=2),\n",
    "  Conv2D(filters=64, kernel_size=3, padding='SAME', activation='relu'),\n",
    "  Flatten(),\n",
    "  Dense(units=64, activation='relu'),\n",
    "  Dense(units=10, activation='softmax'),\n",
    "    \n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer = 'SGD', \n",
    "    metrics = ['accuracy']) \n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17afad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 64)        3200      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,028,874\n",
      "Trainable params: 1,028,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "  Conv2D(filters=64, kernel_size=7, padding='SAME', activation='relu',input_shape=[28, 28, 1]),\n",
    "  MaxPool2D(pool_size=2),\n",
    "  Conv2D(filters=128, kernel_size=3, padding='SAME', activation='relu'),\n",
    "  Conv2D(filters=128, kernel_size=3, padding='SAME', activation='relu'),\n",
    "  MaxPool2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(units=128, activation='relu'),\n",
    "  Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "model3.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer = 'nadam', \n",
    "    metrics = ['accuracy']) \n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e88898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                200768    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,162\n",
      "Trainable params: 257,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = model2\n",
    "\n",
    "model4.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer = 'RMSprop', \n",
    "    metrics = ['accuracy']) \n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209c8a8",
   "metadata": {},
   "source": [
    "## STEP 4\n",
    "\n",
    "### All four models are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5357185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.1832 - accuracy: 0.9458 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 29s 17ms/step - loss: 0.0618 - accuracy: 0.9805 - val_loss: 0.0588 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 29s 17ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0539 - val_accuracy: 0.9868\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 29s 17ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0572 - val_accuracy: 0.9856\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0589 - val_accuracy: 0.9840\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0440 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0531 - val_accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0596 - val_accuracy: 0.9872\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 29s 17ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0693 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 30s 18ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0713 - val_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "fit1 = model1.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8303b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 53s 30ms/step - loss: 0.1252 - accuracy: 0.9625 - val_loss: 0.0497 - val_accuracy: 0.9872\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 53s 31ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.0442 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 54s 31ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.0429 - val_accuracy: 0.9880\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 48s 28ms/step - loss: 0.0322 - accuracy: 0.9923 - val_loss: 0.0512 - val_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 58s 33ms/step - loss: 0.0297 - accuracy: 0.9927 - val_loss: 0.0654 - val_accuracy: 0.9908\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 63s 37ms/step - loss: 0.0263 - accuracy: 0.9943 - val_loss: 0.0875 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 55s 32ms/step - loss: 0.0242 - accuracy: 0.9948 - val_loss: 0.0718 - val_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 54s 32ms/step - loss: 0.0218 - accuracy: 0.9956 - val_loss: 0.1109 - val_accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 56s 32ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 0.1036 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 55s 32ms/step - loss: 0.0219 - accuracy: 0.9967 - val_loss: 0.1113 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "fit2 = model2.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f7b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 217s 126ms/step - loss: 0.1128 - accuracy: 0.9656 - val_loss: 0.0480 - val_accuracy: 0.9872\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 219s 127ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.0442 - val_accuracy: 0.9894\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 221s 129ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.0511 - val_accuracy: 0.9862\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 217s 126ms/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 0.0499 - val_accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 217s 126ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0413 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 221s 128ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0589 - val_accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 225s 131ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0540 - val_accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 226s 131ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.0788 - val_accuracy: 0.9876\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 250s 145ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0720 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 226s 132ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.0660 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "fit3 = model3.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db6a381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 61s 34ms/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 0.2014 - val_accuracy: 0.9926\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 53s 31ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.2121 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 53s 31ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 0.2894 - val_accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 55s 32ms/step - loss: 0.0152 - accuracy: 0.9987 - val_loss: 0.3364 - val_accuracy: 0.9918\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 49s 28ms/step - loss: 0.0148 - accuracy: 0.9988 - val_loss: 0.3600 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 64s 37ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 0.3302 - val_accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 65s 38ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: 0.2562 - val_accuracy: 0.9936\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 51s 30ms/step - loss: 0.0163 - accuracy: 0.9989 - val_loss: 0.4592 - val_accuracy: 0.9910\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 64s 37ms/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.3975 - val_accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 77s 45ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.3838 - val_accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "fit4 = model4.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254de5a",
   "metadata": {},
   "source": [
    "## STEP 5:\n",
    "\n",
    "### Evaluation of all four models are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584dc500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 1216.3678 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1216.3677978515625, 0.9857000112533569]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "826afb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 72985.4766 - accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[72985.4765625, 0.9914000034332275]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a581e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 34ms/step - loss: 5167.6729 - accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5167.6728515625, 0.9896000027656555]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27822d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 14ms/step - loss: 36147.9922 - accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36147.9921875, 0.9912999868392944]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e8082",
   "metadata": {},
   "source": [
    "## STEP 6: \n",
    "    \n",
    "### Calculation of other performance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f86c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = model1.predict(X_test)\n",
    "y_pred_2 = model2.predict(X_test)\n",
    "y_pred_3 = model3.predict(X_test)\n",
    "y_pred_4 = model4.predict(X_test)\n",
    "\n",
    "predictions1 = []\n",
    "predictions2 = []\n",
    "predictions3 = []\n",
    "predictions4 = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "   predictions1.append(np.argmax(y_pred_1[i]))\n",
    "   predictions2.append(np.argmax(y_pred_2[i]))\n",
    "   predictions3.append(np.argmax(y_pred_3[i]))\n",
    "   predictions4.append(np.argmax(y_pred_4[i]))\n",
    "    \n",
    "predictions1 = np.array(predictions1)\n",
    "predictions2 = np.array(predictions2)\n",
    "predictions3 = np.array(predictions3)\n",
    "predictions4 = np.array(predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1af80d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE 1\n",
      "Precision Score:  0.9856145251517237\n",
      "Recall Score:  0.9855657281003799\n",
      "F1 Score:  0.9855656351634581\n"
     ]
    }
   ],
   "source": [
    "print('ARCHITECTURE 1')\n",
    "print('Precision Score: ', precision_score(y_test_mnist, predictions1, average=\"macro\"))\n",
    "print('Recall Score: ', recall_score(y_test_mnist, predictions1, average='macro'))\n",
    "print('F1 Score: ',f1_score(y_test_mnist, predictions1, average='macro'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f47fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE 2\n",
      "Precision Score:  0.9913085526981344\n",
      "Recall Score:  0.9914051198030028\n",
      "F1 Score:  0.9913501515297763\n"
     ]
    }
   ],
   "source": [
    "print('ARCHITECTURE 2')\n",
    "print('Precision Score: ', precision_score(y_test_mnist, predictions2, average=\"macro\"))\n",
    "print('Recall Score: ', recall_score(y_test_mnist, predictions2, average='macro'))\n",
    "print('F1 Score: ',f1_score(y_test_mnist, predictions2, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29f59bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE 3\n",
      "Precision Score:  0.9896762393529276\n",
      "Recall Score:  0.9895479526605777\n",
      "F1 Score:  0.9895914158187002\n"
     ]
    }
   ],
   "source": [
    "print('ARCHITECTURE 3')\n",
    "print('Precision Score: ', precision_score(y_test_mnist, predictions3, average=\"macro\"))\n",
    "print('Recall Score: ', recall_score(y_test_mnist, predictions3, average='macro'))\n",
    "print('F1 Score: ',f1_score(y_test_mnist, predictions3, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d17ab7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE 4\n",
      "Precision Score:  0.9913225708483908\n",
      "Recall Score:  0.9911679499746955\n",
      "F1 Score:  0.9912371900153272\n"
     ]
    }
   ],
   "source": [
    "print('ARCHITECTURE 4')\n",
    "print('Precision Score: ', precision_score(y_test_mnist, predictions4, average=\"macro\"))\n",
    "print('Recall Score: ', recall_score(y_test_mnist, predictions4, average='macro'))\n",
    "print('F1 Score: ',f1_score(y_test_mnist, predictions4, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d2db440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], cmap='gray')      #the image at X-test[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e435908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d811fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c449d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da0030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2dfc75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
